{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d7584-44da-42a8-9380-d6a0cfd0fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras\n",
    "!pip install pillow\n",
    "!pip install tensorflow-model-optimization tf-keras\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae32778-c61d-4da2-96f8-f0b3f9350aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f9277-9c24-4895-9887-66cdbe1da417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_dir = 'dataset_ab'\n",
    "train_dir = dataset_dir \n",
    "val_dir = dataset_dir  # You can split data into train/val if needed\n",
    "\n",
    "# Image parameters\n",
    "img_height, img_width = 96, 96  # Adjust as needed\n",
    "batch_size = 32\n",
    "\n",
    "def to_grayscale(image):\n",
    "    # image = tf.image.rgb_to_grayscale(image)\n",
    "    return image\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=to_grayscale,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=to_grayscale\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for 2 classes\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for 2 classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d6eda-0f7f-4ff5-b9f0-b7d4ec6c4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained MobileNetV3Small\n",
    "base_model = MobileNetV3Small(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(32, kernel_regularizer = regularizers.l2(l2 = 0.016),activity_regularizer=regularizers.l1(l1 = 0.006),\n",
    "                bias_regularizer=regularizers.l1(l1 = 0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.4, seed=69)(x)       \n",
    "\n",
    "output=Dense(2, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,  # Train for a few more epochs\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881f9dc-2bbb-44da-9033-82a15f5751bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import saving\n",
    "\n",
    "# Save the model\n",
    "try:\n",
    "    #model.save(\"model_outputs/mobilenetv3_simple_ab.keras\")    \n",
    "except:\n",
    "    @saving.register_keras_serializable()\n",
    "    def F1_score(y_true, y_pred): #taken from old keras source code\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "        return f1_val\n",
    "    \n",
    "    model = tf.keras.models.load_model('model_outputs/mobilenetv3_simple_ab.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bbac0-d261-420c-8d02-792b7f814b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Define a representative dataset generator\n",
    "def representative_dataset():\n",
    "    dataset_list = tf.data.Dataset.list_files(dataset_dir + '/*/*')\n",
    "    for i in range(2000):\n",
    "        image_path = next(iter(dataset_list)).numpy().decode(\"utf-8\")\n",
    "        img = load_img(image_path, target_size=(img_height, img_width))\n",
    "        img = img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        yield [img.astype(np.float32)]\n",
    "        \n",
    "# Create the TFLite converter with INT8 quantization and representative dataset\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  \n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()   \n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model_outputs/mobilenetv3_simple_ab.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "470e9b33-b8d1-454a-9124-1b927178847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "[[0.04815346 0.9518465 ]]\n",
      "['cat', 'not_cat']\n",
      "Predicted class: not_cat (confidence: 0.95)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Testing block\n",
    "def test_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image, preprocesses it, and predicts its class using the trained model.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "    \"\"\"\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    class_index = np.argmax(prediction)\n",
    "    class_labels = list(train_generator.class_indices.keys())  # Get class labels\n",
    "    confidence = np.max(prediction)  # Get the highest probability\n",
    "\n",
    "    print(prediction);\n",
    "    print(class_labels);\n",
    "    print(\"Predicted class: %s (confidence: %.2f)\" % (class_labels[class_index], confidence))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_image('test_inputs/not_cat2.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73dc8135-a62e-471b-8e34-0a5fa1081239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.lite.python.util import convert_bytes_to_c_source\n",
    "\n",
    "file_name = 'model'\n",
    "source_text, header_text = convert_bytes_to_c_source(tflite_model,  file_name)\n",
    "\n",
    "with  open('model_outputs/' + file_name + '.h',  'w')  as  file:\n",
    "    file.write(header_text)\n",
    "\n",
    "with  open('model_outputs/' + file_name + '.cc',  'w')  as  file:\n",
    "    file.write(source_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
